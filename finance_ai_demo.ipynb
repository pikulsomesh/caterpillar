{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf178da",
   "metadata": {},
   "source": [
    "# AI-Powered Financial Analysis with PyCaret\n",
    "\n",
    "## A Hands-on Tutorial for Finance Professionals\n",
    "\n",
    "This notebook demonstrates how to leverage artificial intelligence and machine learning for financial time series analysis using PyCaret, a low-code machine learning library in Python.\n",
    "\n",
    "### What You'll Learn:\n",
    "- Installing and setting up PyCaret for time series analysis\n",
    "- Loading and exploring financial data\n",
    "- Preprocessing financial time series data\n",
    "- Training and comparing multiple forecasting models\n",
    "- Evaluating model performance with financial metrics\n",
    "- Generating and visualizing future predictions\n",
    "- Interpreting model results for financial decision-making"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bb397",
   "metadata": {},
   "source": [
    "## 1. Installing Required Libraries\n",
    "\n",
    "First, we need to install PyCaret and other necessary libraries. PyCaret is a low-code machine learning library that automates machine learning workflows and makes it easier to implement complex models.\n",
    "\n",
    "> **Note**: This installation may take a few minutes to complete. You only need to run this cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pycaret[full]\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec3996",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Now let's import the necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d71340",
   "metadata": {},
   "source": [
    "## 3. Load Financial Dataset\n",
    "\n",
    "We'll load our financial dataset that contains historical stock prices and other financial metrics. This data will be used to train our time series forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the financial dataset\n",
    "df = pd.read_csv('financial_data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4efb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set Date as the index\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Check the updated dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85254228",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "Before building our forecasting models, let's explore the dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfaacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0] if any(missing_values > 0) else \"No missing values found!\")\n",
    "\n",
    "# Get statistical summary of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the stock price trend\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df.index, df['Stock_Price'], linewidth=2, color='#1f77b4')\n",
    "plt.title('Stock Price Trend Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive plot with Plotly\n",
    "fig = px.line(df, y='Stock_Price', title='Interactive Stock Price Trend')\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Stock Price ($)',\n",
    "    hovermode='x unified',\n",
    "    width=900,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Financial Metrics', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89debfa4",
   "metadata": {},
   "source": [
    "## 5. Time Series Decomposition\n",
    "\n",
    "Let's decompose our time series to understand its components: trend, seasonality, and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library for time series decomposition\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Perform time series decomposition\n",
    "decomposition = seasonal_decompose(df['Stock_Price'], model='multiplicative', period=12)\n",
    "\n",
    "# Plot the decomposition\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "decomposition.observed.plot(ax=ax1)\n",
    "ax1.set_title('Observed', fontsize=14)\n",
    "ax1.set_ylabel('Stock Price')\n",
    "\n",
    "decomposition.trend.plot(ax=ax2)\n",
    "ax2.set_title('Trend', fontsize=14)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "decomposition.seasonal.plot(ax=ax3)\n",
    "ax3.set_title('Seasonality', fontsize=14)\n",
    "ax3.set_ylabel('Seasonality')\n",
    "\n",
    "decomposition.resid.plot(ax=ax4)\n",
    "ax4.set_title('Residuals', fontsize=14)\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ae12c",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Before setting up our time series models, let's create some additional features that might help improve our forecasting accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "# Extract time-based features\n",
    "df_fe['Month'] = df_fe.index.month\n",
    "df_fe['Quarter'] = df_fe.index.quarter\n",
    "df_fe['Year'] = df_fe.index.year\n",
    "df_fe['DayOfYear'] = df_fe.index.dayofyear\n",
    "\n",
    "# Calculate moving averages\n",
    "df_fe['MA7'] = df_fe['Stock_Price'].rolling(window=7).mean()\n",
    "df_fe['MA30'] = df_fe['Stock_Price'].rolling(window=4).mean()  # Using 4 as we have weekly data\n",
    "\n",
    "# Calculate price momentum (% change)\n",
    "df_fe['Price_Momentum'] = df_fe['Stock_Price'].pct_change(periods=4)  # 4-period momentum\n",
    "\n",
    "# Calculate volatility (standard deviation over a window)\n",
    "df_fe['Volatility'] = df_fe['Stock_Price'].rolling(window=4).std()\n",
    "\n",
    "# Drop rows with NaN values resulting from the rolling calculations\n",
    "df_fe = df_fe.dropna()\n",
    "\n",
    "# Display the first few rows of the feature-engineered dataframe\n",
    "df_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ceb212",
   "metadata": {},
   "source": [
    "## 7. Setting Up PyCaret for Time Series Analysis\n",
    "\n",
    "Now we'll import PyCaret's time series module and set up our forecasting environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccf1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyCaret's time series module\n",
    "from pycaret.time_series import *\n",
    "\n",
    "# Note: If you encounter an error, please restart the kernel and run all cells\n",
    "print(\"PyCaret time series module imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the time series experiment\n",
    "# We'll focus on forecasting the stock price\n",
    "\n",
    "# Create a time series dataframe with just the target variable\n",
    "ts_data = df[['Stock_Price']].copy()\n",
    "\n",
    "# Setup the time series experiment\n",
    "exp_name = setup(data=ts_data, \n",
    "                target='Stock_Price',  # Column to forecast\n",
    "                fh=12,                # Forecast horizon - 12 periods ahead\n",
    "                fold=3,               # Number of folds for cross-validation\n",
    "                seasonal_period='W',  # Weekly data\n",
    "                transform_target='box-cox',  # Apply Box-Cox transformation to stabilize variance\n",
    "                session_id=123)       # For reproducibility\n",
    "\n",
    "# Check the setup summary\n",
    "summary = pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc5e25",
   "metadata": {},
   "source": [
    "## 8. Train and Compare Time Series Models\n",
    "\n",
    "Let's train multiple time series forecasting models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare all available models\n",
    "best_models = compare_models(n_select=3)  # Select top 3 models\n",
    "\n",
    "# Display the best models and their performance metrics\n",
    "print(\"Top 3 best performing models:\")\n",
    "for i, model in enumerate(best_models):\n",
    "    print(f\"Model {i+1}: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cddc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best model in more detail\n",
    "best_model = best_models[0]  # Select the best model\n",
    "\n",
    "# Plot forecast\n",
    "plot_model(best_model, plot='forecast', data_kwargs={'fh': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals to check model quality\n",
    "plot_model(best_model, plot='residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a503b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot diagnostics for the best model\n",
    "plot_model(best_model, plot='diagnostics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a579d05",
   "metadata": {},
   "source": [
    "## 9. Finalize the Best Model and Generate Future Forecasts\n",
    "\n",
    "We'll finalize our best model by training it on the entire dataset and then generate future forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the model (train on the entire dataset)\n",
    "final_model = finalize_model(best_model)\n",
    "\n",
    "# Generate future forecasts for the next 12 periods\n",
    "future_forecasts = predict_model(final_model, fh=12)\n",
    "\n",
    "# Display the forecasts\n",
    "print(\"Future Stock Price Forecasts:\")\n",
    "future_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7714cf",
   "metadata": {},
   "source": [
    "## 10. Explore Different Time Series Models\n",
    "\n",
    "Let's manually create and tune a few specific models to see if we can improve our forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ARIMA model\n",
    "arima = create_model('arima')\n",
    "\n",
    "# Plot ARIMA forecast\n",
    "plot_model(arima, plot='forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310019f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Prophet model\n",
    "prophet = create_model('prophet')\n",
    "\n",
    "# Plot Prophet forecast\n",
    "plot_model(prophet, plot='forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0541c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ETS (Error, Trend, Seasonality) model\n",
    "ets = create_model('ets')\n",
    "\n",
    "# Plot ETS forecast\n",
    "plot_model(ets, plot='forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33744c5e",
   "metadata": {},
   "source": [
    "## 11. Create Ensemble Models\n",
    "\n",
    "Let's create an ensemble of our top models to potentially improve forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blended ensemble of the top 3 models\n",
    "blended = blend_models(best_models)\n",
    "\n",
    "# Plot ensemble forecast\n",
    "plot_model(blended, plot='forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467bc2a",
   "metadata": {},
   "source": [
    "## 12. Financial Interpretation of Forecasts\n",
    "\n",
    "Let's analyze our forecasts from a financial perspective and discuss how they can be used for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ensemble forecasts\n",
    "ensemble_forecasts = predict_model(blended, fh=12)\n",
    "\n",
    "# Calculate key financial metrics\n",
    "last_known_price = ts_data['Stock_Price'].iloc[-1]\n",
    "forecast_end_price = ensemble_forecasts['y_pred'].iloc[-1]\n",
    "\n",
    "# Calculate expected return\n",
    "expected_return = (forecast_end_price - last_known_price) / last_known_price * 100\n",
    "\n",
    "# Calculate volatility of forecasts\n",
    "forecast_volatility = ensemble_forecasts['y_pred'].std() / ensemble_forecasts['y_pred'].mean() * 100\n",
    "\n",
    "# Display financial insights\n",
    "print(f\"Last known stock price: ${last_known_price:.2f}\")\n",
    "print(f\"Forecasted price after 12 periods: ${forecast_end_price:.2f}\")\n",
    "print(f\"Expected return over forecast horizon: {expected_return:.2f}%\")\n",
    "print(f\"Forecast volatility: {forecast_volatility:.2f}%\")\n",
    "\n",
    "# Determine trend direction\n",
    "trend = \"Upward\" if expected_return > 0 else \"Downward\"\n",
    "print(f\"Overall trend direction: {trend}\")\n",
    "\n",
    "# Calculate monthly growth rate (assuming weekly data)\n",
    "monthly_growth = (forecast_end_price / last_known_price) ** (12/52) - 1\n",
    "print(f\"Implied monthly growth rate: {monthly_growth*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a simple risk assessment\n",
    "\n",
    "# Create multiple simulation paths using bootstrap\n",
    "import random\n",
    "n_simulations = 100\n",
    "simulation_paths = []\n",
    "\n",
    "# Use the residuals from our best model to create simulated paths\n",
    "residuals = pd.Series(best_model.resid()) if hasattr(best_model, 'resid') else pd.Series(np.random.normal(0, forecast_volatility/100*last_known_price, 100))\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Start with the forecast values\n",
    "    sim_path = ensemble_forecasts['y_pred'].copy()\n",
    "    \n",
    "    # Add random residuals to create a simulated path\n",
    "    for j in range(len(sim_path)):\n",
    "        sim_path.iloc[j] += random.choice(residuals)\n",
    "    \n",
    "    simulation_paths.append(sim_path)\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "sim_df = pd.DataFrame(simulation_paths).T\n",
    "sim_df.index = ensemble_forecasts.index\n",
    "\n",
    "# Calculate Value at Risk (VaR) at 95% confidence level\n",
    "final_values = [path.iloc[-1] for path in simulation_paths]\n",
    "VaR_95 = np.percentile(final_values, 5)\n",
    "profit_potential = np.percentile(final_values, 95)\n",
    "\n",
    "# Calculate the probability of loss\n",
    "loss_probability = sum(1 for val in final_values if val < last_known_price) / len(final_values) * 100\n",
    "\n",
    "# Print risk metrics\n",
    "print(f\"Value at Risk (95% confidence): ${(last_known_price - VaR_95):.2f} per share\")\n",
    "print(f\"Potential upside (95% confidence): ${(profit_potential - last_known_price):.2f} per share\")\n",
    "print(f\"Probability of negative return: {loss_probability:.2f}%\")\n",
    "\n",
    "# Plot simulation paths\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot historical data\n",
    "plt.plot(ts_data.index, ts_data['Stock_Price'], 'b-', linewidth=2, label='Historical')\n",
    "\n",
    "# Plot each simulation path with transparency\n",
    "for i in range(min(50, n_simulations)):  # Plot only 50 paths for clarity\n",
    "    plt.plot(sim_df.index, sim_df.iloc[:, i], 'r-', alpha=0.1)\n",
    "\n",
    "# Plot the mean forecast\n",
    "plt.plot(ensemble_forecasts.index, ensemble_forecasts['y_pred'], 'g--', linewidth=2, label='Mean Forecast')\n",
    "\n",
    "# Add VaR and profit potential lines\n",
    "plt.axhline(y=VaR_95, color='orange', linestyle='--', label=f'5% VaR: ${VaR_95:.2f}')\n",
    "plt.axhline(y=profit_potential, color='green', linestyle='--', label=f'95% Upside: ${profit_potential:.2f}')\n",
    "\n",
    "plt.title('Stock Price Forecast with Monte Carlo Simulations', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966266ca",
   "metadata": {},
   "source": [
    "## 13. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "\n",
    "1. Load and explore financial time series data\n",
    "2. Perform time series decomposition to understand underlying patterns\n",
    "3. Create additional features to enhance model performance\n",
    "4. Set up PyCaret for automated time series forecasting\n",
    "5. Train and compare multiple forecasting models\n",
    "6. Fine-tune models for better performance\n",
    "7. Create ensemble models to improve forecast accuracy\n",
    "8. Generate and visualize future forecasts\n",
    "9. Interpret forecasts from a financial perspective\n",
    "10. Assess risk using simulation techniques\n",
    "\n",
    "### Potential Next Steps:\n",
    "\n",
    "- Include external factors such as economic indicators or market sentiment\n",
    "- Implement more advanced feature engineering techniques\n",
    "- Explore deep learning models for time series forecasting\n",
    "- Develop a portfolio optimization strategy based on the forecasts\n",
    "- Create an automated trading strategy using the forecasting models\n",
    "- Implement backtesting to validate model performance on historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24570a16",
   "metadata": {},
   "source": [
    "## 14. Saving and Loading the Model\n",
    "\n",
    "Finally, let's see how to save our best model for future use and how to load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c73588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the finalized model\n",
    "from pycaret.time_series import save_model, load_model\n",
    "\n",
    "# Save the model\n",
    "save_model(final_model, 'financial_forecasting_model')\n",
    "\n",
    "# How to load the model later (for demonstration)\n",
    "loaded_model = load_model('financial_forecasting_model')\n",
    "\n",
    "# Test the loaded model by making a prediction\n",
    "new_forecast = predict_model(loaded_model, fh=12)\n",
    "print(\"Forecast from loaded model:\")\n",
    "new_forecast.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
